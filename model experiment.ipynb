{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "\n",
    "## Model choice w/ hyperparam optimization on diagnosing emotion\n",
    "\n",
    "Due to the past assignments I have been lead to believe that extreem gradient boosting (XGB) will lead to large improvements over other model choices, though I will be trying several out of the box models within sklearn and use Bayesian Optimization to tune the hyperparameters.\n",
    "\n",
    "### Bayesian Optimization\n",
    "\n",
    "Bayesian Optimization is a non-gradient-based arbitrary function optimization algorithm that I will be using to tune the hyperparameters of each model (to the extent that they have them). This is particularly useful in tuning the large amount of hyperparameters in XGB/any algorithm with a large amount of hyperparameters.\n",
    "\n",
    "## Models to be used\n",
    "The models to be experimented with are as follows:\n",
    "- SVC\n",
    "- XGB\n",
    "- Naive Bayes\n",
    "- Random Forest Classifier\n",
    "- Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas\n",
    "from sklearn import svm, naive_bayes, ensemble, neural_network, metrics\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data, meta = arff.loadarff('emobase2010.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pandas.DataFrame.from_records(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns = data.dtype.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove neutral, unknown and other classes\n",
    "a = df['class']!=b'NEU'\n",
    "b = df['class']!=b'UNK'\n",
    "c = df['class']!=b'OTH'\n",
    "df = df.loc[a&b&c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'DIS'    467\n",
       "b'SUR'    452\n",
       "b'ACC'    450\n",
       "b'ANT'    412\n",
       "b'SAD'    285\n",
       "b'FEA'    239\n",
       "b'JOY'    226\n",
       "b'ANG'    212\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adata = df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, labels = np.split(adata, [-1], axis=1)\n",
    "labels = [s for s in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2743, 1)\n",
      "[0 3 0 ..., 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(labels))\n",
    "le = LabelEncoder()\n",
    "labels = [s[0] for s in labels]\n",
    "le.fit(labels)\n",
    "labels = le.transform(labels)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wclf = svm.SVC(kernel='linear', class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = cross_val_predict(wclf, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24462267590229675"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(labels, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17025154939846884 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "# rough baseline -- majority class\n",
    "print(467/len(labels), 1/6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright so this is a pretty good score considering the rough baseline, now let's try optimizing the hyperparameters with Bayesian Optimization. Just as a warning this is going to run the above code around 15 times, so either be prepared to wait a couple of hours (I ran it overnight) or just observe the results from this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svceval(C, gamma):\n",
    "    \n",
    "    params['C'] = float(C)\n",
    "    params['gamma'] = float(gamma)\n",
    "    \n",
    "    wclf = svm.SVC(kernel='linear', class_weight='balanced', **params)\n",
    "    \n",
    "    predicted = cross_val_predict(wclf, features, labels)\n",
    "    \n",
    "    return metrics.accuracy_score(labels, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |         C |     gamma | \n"
     ]
    }
   ],
   "source": [
    "num_rounds = 3000\n",
    "random_state = 2017\n",
    "num_iter = 10\n",
    "init_points = 5\n",
    "params = {}\n",
    "\n",
    "xgbBO = BayesianOptimization(svceval, {'C': (0.001, 100), \n",
    "                                       'gamma': (0.0001, 0.1)\n",
    "                                        })\n",
    "\n",
    "xgbBO.maximize(init_points=init_points, n_iter=num_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wclf = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ac629811cebc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    399\u001b[0m     prediction_blocks = parallel(delayed(_fit_and_predict)(\n\u001b[1;32m    400\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method)\n\u001b[0;32m--> 401\u001b[0;31m         for train, test in cv_iter)\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;31m# Concatenate the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/xgboost-0.6-py3.5.egg/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose)\u001b[0m\n\u001b[1;32m    443\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                               verbose_eval=verbose)\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/xgboost-0.6-py3.5.egg/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/xgboost-0.6-py3.5.egg/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/xgboost-0.6-py3.5.egg/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predicted = cross_val_predict(wclf, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7b7a97317deb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predicted' is not defined"
     ]
    }
   ],
   "source": [
    "metrics.accuracy_score(labels, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ok, so we can see that the regular XGB improves the baseline pretty dramatically. Now let's define a function for our Bayesian Optimizer to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgbeval(min_child_weight,\n",
    "                 colsample_bytree,\n",
    "                 max_depth,\n",
    "                 subsample,\n",
    "                 gamma):\n",
    "\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['colsample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['subsample'] = max(min(subsample, 1), 0)\n",
    "    params['gamma'] = max(gamma, 0)\n",
    "    wclf = xgb.XGBClassifier(**params)\n",
    "    \n",
    "    predicted = cross_val_predict(wclf, features, labels)\n",
    "    \n",
    "    return metrics.accuracy_score(labels, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we optimize the function, warning: this will take a super long time to run. It may be advisable to run it on a server or just simply look at the output attatched to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "    1 | 04m48s | \u001b[35m   0.31134\u001b[0m | \u001b[32m            0.3366\u001b[0m | \u001b[32m   2.1001\u001b[0m | \u001b[32m     9.4543\u001b[0m | \u001b[32m            6.0659\u001b[0m | \u001b[32m     0.8636\u001b[0m | \n",
      "    2 | 08m54s |    0.29202 |             0.8072 |    0.7104 |      8.9388 |             2.7824 |      0.6164 | \n",
      "    3 | 03m07s |    0.30587 |             0.2928 |    5.1080 |      9.3488 |             9.3586 |      0.5261 | \n",
      "    4 | 06m07s |    0.29821 |             0.7249 |    8.5479 |     14.4441 |            12.0732 |      0.5231 | \n",
      "    5 | 03m26s |    0.30623 |             0.4091 |    2.7943 |     10.7828 |            19.6571 |      0.6007 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "    6 | 02m05s |    0.30660 |             0.1000 |    0.0000 |     14.9379 |            13.0542 |      0.6680 | \n",
      "    7 | 01m45s |    0.30222 |             0.1000 |   10.0000 |      5.0000 |            20.0000 |      1.0000 | \n",
      "    8 | 07m38s |    0.30113 |             1.0000 |    0.0000 |      5.0000 |            20.0000 |      1.0000 | \n",
      "    9 | 04m26s |    0.29894 |             0.1736 |    9.7862 |     14.2653 |             1.1187 |      0.9952 | \n",
      "   10 | 94m00s |    0.29603 |             0.2528 |    9.8876 |      5.2622 |             1.4550 |      0.9842 | \n",
      "   11 | 02m45s |    0.30623 |             0.1567 |    8.5372 |     14.9318 |            19.8032 |      0.9669 | \n",
      "   12 | 02m02s |    0.29821 |             0.1320 |    0.0013 |      5.2846 |            12.4111 |      0.9144 | \n",
      "   13 | 02m37s |    0.31061 |             0.1760 |    0.3862 |     14.8381 |            19.7863 |      0.8938 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  3.55870347e-05]), 'funcalls': 52, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   14 | 02m44s |    0.31061 |             0.1076 |    2.6737 |     14.6929 |             7.0232 |      0.9564 | \n",
      "   15 | 13m30s |    0.30806 |             0.9887 |    1.2976 |     11.8162 |             8.8511 |      0.9865 | \n"
     ]
    }
   ],
   "source": [
    "num_rounds = 3000\n",
    "random_state = 2017\n",
    "num_iter = 10\n",
    "init_points = 5\n",
    "params = {}\n",
    "\n",
    "xgbBO = BayesianOptimization(xgbeval, {'min_child_weight': (1, 20),\n",
    "                                                'colsample_bytree': (0.1, 1),\n",
    "                                                'max_depth': (5, 15),\n",
    "                                                'subsample': (0.5, 1),\n",
    "                                                'gamma': (0, 10)\n",
    "                                                })\n",
    "xgbBO.maximize(init_points=init_points, n_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results\n",
      "XGBOOST: 0.311338\n",
      "Best Params: {'subsample': 0.86358306525373618, 'colsample_bytree': 0.33658558928849269, 'max_depth': 9.4543347834429881, 'min_child_weight': 6.0659314521001315, 'gamma': 2.1000619104831797}\n"
     ]
    }
   ],
   "source": [
    "print('Final Results')\n",
    "print('XGBOOST: %f' % xgbBO.res['max']['max_val'])\n",
    "print('Best Params: {}'.format(xgbBO.res['max']['max_params']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, a little dissapointing that a couple hours only got us about another percent of accuracy out of it. Lets repeat the process for other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wclf = naive_bayes.GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = cross_val_predict(wclf, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20889537003281078"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(labels, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so that's not so good, and the downside is that because the Naive Bayes is so simple it doesn't allow for hyperparameter tuning as there are no hyperparameters to tune. We can use this as a good baseline however. Let's move on to something more interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "Kind of the little brother of XGB, Random Forests represent a very reasonable model choice for a lot of tasks. With the addition of many hyperparameters we can see how much more accuracy we can squeeze out with Bayesian Optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wclf = ensemble.RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = cross_val_predict(wclf, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23769595333576377"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(labels, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so that's with entirely default parameters, now let's tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rfeval(n_estimators,\n",
    "          max_depth,\n",
    "          min_samples_split,\n",
    "          min_samples_leaf,\n",
    "          min_weight_fraction_leaf,\n",
    "          min_impurity_split):\n",
    "    \n",
    "    params['n_estimators'] = int(n_estimators)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['min_samples_split'] = float(min_samples_split)\n",
    "    params['min_samples_leaf'] = float(min_samples_leaf)\n",
    "    params['min_weight_fraction_leaf'] = float(min_weight_fraction_leaf)\n",
    "    params['min_impurity_split'] = float(min_impurity_split)\n",
    "    wclf = ensemble.RandomForestClassifier(**params)\n",
    "    \n",
    "    predicted = cross_val_predict(wclf, features, labels)\n",
    "    \n",
    "    return metrics.accuracy_score(labels, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   max_depth |   min_impurity_split |   min_samples_leaf |   min_samples_split |   min_weight_fraction_leaf |   n_estimators | \n",
      "    1 | 00m03s | \u001b[35m   0.17025\u001b[0m | \u001b[32m     8.2271\u001b[0m | \u001b[32m              1.3648\u001b[0m | \u001b[32m            0.1369\u001b[0m | \u001b[32m             0.7024\u001b[0m | \u001b[32m                    0.4156\u001b[0m | \u001b[32m        6.2759\u001b[0m | \n",
      "    2 | 00m03s |    0.17025 |      8.9579 |               4.0618 |             0.4170 |              0.7289 |                     0.4430 |        19.2143 | \n",
      "    3 | 00m02s |    0.17025 |      5.0506 |               3.1692 |             0.4092 |              0.5973 |                     0.4241 |        11.2262 | \n",
      "    4 | 00m03s | \u001b[35m   0.23077\u001b[0m | \u001b[32m    11.5825\u001b[0m | \u001b[32m              0.7003\u001b[0m | \u001b[32m            0.0880\u001b[0m | \u001b[32m             0.5905\u001b[0m | \u001b[32m                    0.2103\u001b[0m | \u001b[32m       14.3346\u001b[0m | \n",
      "    5 | 00m02s |    0.16843 |     12.9565 |               1.5326 |             0.3901 |              0.5660 |                     0.2164 |         2.6063 | \n",
      "    6 | 00m03s |    0.17025 |      6.3681 |               1.7784 |             0.4029 |              0.2128 |                     0.3416 |        15.9320 | \n",
      "    7 | 00m03s |    0.17025 |      6.5224 |               4.9992 |             0.4784 |              0.9419 |                     0.1658 |         8.6628 | \n",
      "    8 | 00m03s |    0.17025 |      9.8737 |               1.8264 |             0.1284 |              0.4698 |                     0.0814 |         6.7998 | \n",
      "    9 | 00m02s |    0.16843 |     13.4392 |               2.9592 |             0.3172 |              0.1896 |                     0.3485 |        12.6945 | \n",
      "   10 | 00m02s |    0.17025 |      9.9343 |               4.5726 |             0.2107 |              0.1686 |                     0.3318 |        14.0482 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   max_depth |   min_impurity_split |   min_samples_leaf |   min_samples_split |   min_weight_fraction_leaf |   n_estimators | \n",
      "   11 | 00m22s |    0.17025 |     15.0000 |               0.0000 |             0.0000 |              1.0000 |                     0.0000 |        20.0000 | \n",
      "   12 | 00m11s |    0.16624 |      5.0000 |               0.0000 |             0.0000 |              1.0000 |                     0.0000 |         1.0000 | \n",
      "   13 | 00m11s |    0.17025 |     15.0000 |               0.0000 |             0.0000 |              1.0000 |                     0.0000 |         9.4732 | \n",
      "   14 | 00m13s |    0.17025 |     10.2060 |               0.0000 |             0.5000 |              1.0000 |                     0.0000 |        15.5820 | \n",
      "   15 | 00m17s |    0.16806 |      5.0000 |               5.0000 |             0.0000 |              0.0000 |                     0.5000 |         1.0000 | \n",
      "   16 | 00m23s |    0.17025 |      5.0000 |               5.0000 |             0.0000 |              0.0000 |                     0.0000 |        20.0000 | \n",
      "   17 | 00m22s |    0.16405 |     15.0000 |               5.0000 |             0.0000 |              1.0000 |                     0.5000 |         1.0000 | \n",
      "   18 | 00m17s |    0.19176 |     15.0000 |               0.0000 |             0.0000 |              0.0000 |                     0.5000 |         1.0000 | \n",
      "   19 | 00m16s | \u001b[35m   0.23952\u001b[0m | \u001b[32m    13.6140\u001b[0m | \u001b[32m              0.0000\u001b[0m | \u001b[32m            0.0000\u001b[0m | \u001b[32m             0.0000\u001b[0m | \u001b[32m                    0.5000\u001b[0m | \u001b[32m       15.2473\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  1.50365112e-05]), 'funcalls': 49, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   20 | 00m13s |    0.17025 |     15.0000 |               5.0000 |             0.0000 |              0.0000 |                     0.5000 |        20.0000 | \n",
      "   21 | 00m16s | \u001b[35m   0.24353\u001b[0m | \u001b[32m    11.4489\u001b[0m | \u001b[32m              0.0000\u001b[0m | \u001b[32m            0.0000\u001b[0m | \u001b[32m             0.0000\u001b[0m | \u001b[32m                    0.5000\u001b[0m | \u001b[32m       11.4352\u001b[0m | \n",
      "   22 | 00m15s |    0.24098 |      7.3848 |               0.0000 |             0.0000 |              0.0000 |                     0.5000 |        20.0000 | \n",
      "   23 | 00m14s |    0.23697 |      5.3645 |               0.0000 |             0.0000 |              0.3338 |                     0.5000 |        20.0000 | \n",
      "   24 | 00m11s |    0.22895 |      8.7176 |               0.0000 |             0.0000 |              0.0000 |                     0.5000 |        11.8383 | \n",
      "   25 | 00m13s |    0.17025 |     10.8394 |               0.8673 |             0.0000 |              0.0000 |                     0.5000 |        19.6535 | \n",
      "   26 | 00m17s | \u001b[35m   0.26686\u001b[0m | \u001b[32m    12.0298\u001b[0m | \u001b[32m              0.0000\u001b[0m | \u001b[32m            0.0000\u001b[0m | \u001b[32m             0.0000\u001b[0m | \u001b[32m                    0.0000\u001b[0m | \u001b[32m       13.3269\u001b[0m | \n",
      "   27 | 00m17s |    0.26394 |      5.0000 |               0.0000 |             0.0000 |              0.0000 |                     0.0000 |         8.1535 | \n",
      "   28 | 00m13s | \u001b[35m   0.26941\u001b[0m | \u001b[32m     5.0000\u001b[0m | \u001b[32m              0.0000\u001b[0m | \u001b[32m            0.0000\u001b[0m | \u001b[32m             0.0000\u001b[0m | \u001b[32m                    0.0000\u001b[0m | \u001b[32m        5.5068\u001b[0m | \n",
      "   29 | 00m14s |    0.17025 |      5.0000 |               2.9473 |             0.0000 |              0.0000 |                     0.0000 |         5.8683 | \n",
      "   30 | 00m16s |    0.17025 |      5.0000 |               0.0000 |             0.5000 |              0.0000 |                     0.5000 |         7.2854 | \n",
      "   31 | 00m18s |    0.19686 |      9.8346 |               0.0000 |             0.0000 |              0.0000 |                     0.0000 |         1.0000 | \n",
      "   32 | 00m15s |    0.17025 |      5.0000 |               0.0000 |             0.0000 |              1.0000 |                     0.0000 |        12.6054 | \n",
      "   33 | 00m19s |    0.16843 |     10.4234 |               5.0000 |             0.0000 |              0.0000 |                     0.0000 |         1.0000 | \n",
      "   34 | 00m15s |    0.17025 |     15.0000 |               5.0000 |             0.0000 |              0.0000 |                     0.0000 |         5.9197 | \n",
      "   35 | 00m29s |    0.16843 |      5.0000 |               5.0000 |             0.0000 |              0.0000 |                     0.0000 |        12.3386 | \n"
     ]
    }
   ],
   "source": [
    "num_iter = 25\n",
    "init_points = 10\n",
    "params = {}\n",
    "\n",
    "xgbBO = BayesianOptimization(rfeval, {'n_estimators': (1, 20),\n",
    "                                                'max_depth': (5, 15),\n",
    "                                                'min_samples_split': (1e-10, 1),\n",
    "                                                'min_samples_leaf': (1e-10, 0.5),\n",
    "                                                'min_weight_fraction_leaf': (1e-10, 0.5),\n",
    "                                                'min_impurity_split': (1e-10,5)\n",
    "                                                })\n",
    "xgbBO.maximize(init_points=init_points, n_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Final Results')\n",
    "print('XGBOOST: %f' % xgbBO.res['max']['max_val'])\n",
    "print('Best Params: {}'.format(xgbBO.res['max']['max_params']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to improve it a decent amount, now let's try it on a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wclf = neural_network.MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = cross_val_predict(wclf, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23769595333576377"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(labels, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, doing approximately the same as the Random Forest. Now let's see how much we can improve this baseline with hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nneval(hidden_layer_sizes,\n",
    "          alpha,\n",
    "          max_iter,\n",
    "          momentum\n",
    "          ):\n",
    "    \n",
    "    params['hidden_layer_sizes'] = int(hidden_layer_sizes)\n",
    "    params['alpha'] = float(alpha)\n",
    "    params['max_iter'] = int(max_iter)\n",
    "    params['momentum'] = float(momentum)\n",
    "    wclf = neural_network.MLPClassifier(**params)\n",
    "    \n",
    "    predictions = cross_val_predict(wclf, features, labels)\n",
    "    \n",
    "    return metrics.accuracy_score(labels, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   hidden_layer_sizes |   max_iter |   momentum | \n",
      "    1 | 00m23s | \u001b[35m   0.23770\u001b[0m | \u001b[32m   0.8330\u001b[0m | \u001b[32m            447.3926\u001b[0m | \u001b[32m  564.8413\u001b[0m | \u001b[32m    0.9552\u001b[0m | \n",
      "    2 | 00m31s |    0.23770 |    0.4811 |             581.0781 |   808.9416 |     0.5633 | \n",
      "    3 | 01m41s |    0.23770 |    0.0356 |            1801.2926 |   984.3828 |     0.9246 | \n",
      "    4 | 01m09s |    0.23770 |    0.9591 |            1416.2374 |   767.6943 |     0.5836 | \n",
      "    5 | 01m44s |    0.23770 |    0.8029 |            1822.3162 |   474.8421 |     0.2187 | \n",
      "    6 | 01m03s |    0.23770 |    0.2403 |            1754.1954 |   216.1525 |     0.0673 | \n",
      "    7 | 00m13s |    0.23770 |    0.7234 |             241.7600 |   895.3285 |     0.7591 | \n",
      "    8 | 00m11s |    0.23770 |    0.4555 |             150.0496 |   687.2552 |     0.7285 | \n",
      "    9 | 00m38s |    0.23770 |    0.6559 |             982.8854 |   521.3565 |     0.7709 | \n",
      "   10 | 00m34s |    0.23770 |    0.6695 |             890.0161 |   243.1596 |     0.3932 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   hidden_layer_sizes |   max_iter |   momentum | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   11 | 00m20s |    0.23770 |    0.5110 |               4.7368 |     2.3946 |     0.3529 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   12 | 00m18s |    0.23770 |    0.3663 |            1999.0257 |     1.9800 |     0.1381 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   13 | 00m19s |    0.23770 |    0.7063 |            1299.1278 |     2.2767 |     0.6072 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   14 | 00m16s |    0.23770 |    0.1634 |               1.4881 |   994.9635 |     0.0829 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15 | 00m14s |    0.23770 |    0.5768 |             502.7849 |     2.8394 |     0.1410 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   16 | 01m04s |    0.23770 |    0.1559 |            1051.6425 |   999.8829 |     0.4360 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   17 | 01m30s |    0.23770 |    0.1050 |            1997.0634 |   976.8648 |     0.2026 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   18 | 00m18s |    0.23770 |    0.4589 |               4.7814 |   322.2557 |     0.5049 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19 | 01m14s |    0.23770 |    0.5727 |            1409.7515 |   351.3520 |     0.1234 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   20 | 01m37s |    0.23770 |    0.8234 |            1987.6209 |   363.8301 |     0.2746 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   21 | 00m29s |    0.23770 |    0.1833 |             920.0945 |     7.6615 |     0.7636 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   22 | 00m21s |    0.23770 |    0.9506 |             251.7709 |   139.8792 |     0.0859 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   23 | 00m40s |    0.23770 |    0.1681 |             712.0102 |   991.9642 |     0.2549 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   24 | 01m31s |    0.23770 |    0.1502 |            1984.9260 |   695.8043 |     0.3932 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 | 00m36s |    0.23770 |    0.6451 |             502.0858 |   329.6018 |     0.4787 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   26 | 00m39s |    0.23770 |    0.6072 |             934.3617 |   735.3286 |     0.7345 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   27 | 01m16s |    0.23770 |    0.9751 |            1127.5203 |   256.5993 |     0.5351 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   28 | 00m16s |    0.23770 |    0.0787 |             180.2970 |    50.2458 |     0.6834 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   29 | 00m59s |    0.23770 |    0.8436 |            1194.9331 |   431.5333 |     0.0181 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   30 | 01m20s |    0.23770 |    0.7209 |            1864.1997 |    82.5007 |     0.4808 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   31 | 00m47s |    0.23770 |    0.4402 |             774.5422 |   771.6745 |     0.8210 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   32 | 00m11s |    0.23770 |    0.3048 |              72.0848 |   373.1665 |     0.0597 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   33 | 00m13s |    0.23770 |    0.3147 |              50.8687 |   761.2084 |     0.3827 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   34 | 00m13s |    0.23770 |    0.7960 |              37.1463 |   136.3000 |     0.8085 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   35 | 00m39s |    0.23770 |    0.4523 |            1171.8966 |     9.5495 |     0.7053 | \n"
     ]
    }
   ],
   "source": [
    "num_iter = 25\n",
    "init_points = 10\n",
    "params = {}\n",
    "\n",
    "xgbBO = BayesianOptimization(nneval, {'hidden_layer_sizes': (1, 2000),\n",
    "                                                'alpha': (0, 1),\n",
    "                                                'max_iter': (1, 1000),\n",
    "                                                'momentum': (0, 1),\n",
    "                                                })\n",
    "\n",
    "xgbBO.maximize(init_points=init_points, n_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results\n",
      "XGBOOST: 0.237696\n",
      "Best Params: {'alpha': 0.83300613352786079, 'hidden_layer_sizes': 447.39261592521166, 'max_iter': 564.84132865762592, 'momentum': 0.95519854732881171}\n"
     ]
    }
   ],
   "source": [
    "print('Final Results')\n",
    "print('XGBOOST: %f' % xgbBO.res['max']['max_val'])\n",
    "print('Best Params: {}'.format(xgbBO.res['max']['max_params']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly Bayesian Optimization doesn't seem to help the neural network for several reasons, one of which is that when predicting the level of the max iterations it can cause non-convergence if it sets it too low. It seems that, for neural networks at least, it helps much more to actually know what you're doing when setting the hyperparameters. Bayesian Optimization can theoretically help with setting the proper hidden layer size, which I will test below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nneval(hidden_layer_sizes):\n",
    "    \n",
    "    params['hidden_layer_sizes'] = int(hidden_layer_sizes)\n",
    "    wclf = neural_network.MLPClassifier(**params)\n",
    "    \n",
    "    predictions = cross_val_predict(wclf, features, labels)\n",
    "    \n",
    "    return metrics.accuracy_score(labels, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m----------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   hidden_layer_sizes | \n",
      "    1 | 00m24s | \u001b[35m   0.23770\u001b[0m | \u001b[32m            304.9642\u001b[0m | \n",
      "    2 | 02m21s |    0.23770 |            1866.4436 | \n",
      "    3 | 03m19s |    0.23770 |            1746.9608 | \n",
      "    4 | 00m16s |    0.23770 |             175.0697 | \n",
      "    5 | 01m22s |    0.23770 |            1417.1520 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:565: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    6 | 01m08s |    0.23770 |            1362.9882 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:565: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    7 | 00m56s |    0.23770 |            1735.9870 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:565: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-61-dd7f2def7b04>\", line 7, in <module>\n",
      "    xgbBO.maximize(init_points=init_points, n_iter=num_iter)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/bayes_opt/bayesian_optimization.py\", line 249, in maximize\n",
      "    self.init(init_points)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/bayes_opt/bayesian_optimization.py\", line 104, in init\n",
      "    y_init.append(self.f(**dict(zip(self.keys, x))))\n",
      "  File \"<ipython-input-60-c1bc828c1717>\", line 6, in nneval\n",
      "    predictions = cross_val_predict(wclf, features, labels)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\", line 401, in cross_val_predict\n",
      "    for train, test in cv_iter)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 758, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 608, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 571, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 109, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 326, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\", line 476, in _fit_and_predict\n",
      "    predictions = func(X_test)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py\", line 934, in predict\n",
      "    y_pred = self._predict(X)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py\", line 676, in _predict\n",
      "    self._forward_pass(activations)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py\", line 104, in _forward_pass\n",
      "    self.coefs_[i])\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/utils/extmath.py\", line 189, in safe_sparse_dot\n",
      "    return fast_dot(a, b)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1821, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/inspect.py\", line 1414, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 170, in findsource\n",
      "    file = getsourcefile(object) or getfile(object)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/inspect.py\", line 672, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/inspect.py\", line 709, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/inspect.py\", line 70, in ismodule\n",
      "    return isinstance(object, types.ModuleType)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "num_iter = 10\n",
    "init_points = 5\n",
    "params = {}\n",
    "\n",
    "xgbBO = BayesianOptimization(nneval, {'hidden_layer_sizes': (1, 2000)})\n",
    "\n",
    "xgbBO.maximize(init_points=init_points, n_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a float is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-9afe1b8c2e4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Final Results'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'XGBOOST: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mxgbBO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best Params: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgbBO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: a float is required"
     ]
    }
   ],
   "source": [
    "print('Final Results')\n",
    "print('XGBOOST: %f' % xgbBO.res['max']['max_val'])\n",
    "print('Best Params: {}'.format(xgbBO.res['max']['max_params']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It actually looks like the hidden layer size has extremely little affect on the overall performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "SVC | SVC w/ BO | XGB | XGB w/ BO | NB | RF | RF w/ BO | MLP | MLP w/ BO \n",
    "--- | --- | --- | --- | --- | --- | --- | --- | ---\n",
    "0.245  |    |  0.304  |  0.311  |  0.208  |  0.237  | 0.269  | 0.237  |  0.237"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "As we can see from the above results, XGB has again proved to be the highest performing model. Beyond that, we have seen that Bayesian Optimization can improve the performance of all decision tree based algorithms, but beyond that does not seem to be effective for the MLP. In the next experiment, we will take these results and see how feature normalization/dimensionality reduction will affect our accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
