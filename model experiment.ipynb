{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "\n",
    "## Model choice w/ hyperparam optimization on diagnosing emotion\n",
    "\n",
    "Due to the past assignments I have been lead to believe that extreem gradient boosting (XGB) will lead to large improvements over other model choices, though I will be trying several out of the box models within sklearn and use Bayesian Optimization to tune the hyperparameters.\n",
    "\n",
    "### Bayesian Optimization\n",
    "\n",
    "Bayesian Optimization is a non-gradient-based arbitrary function optimization algorithm that I will be using to tune the hyperparameters of each model (to the extent that they have them). This is particularly useful in tuning the large amount of hyperparameters in XGB/any algorithm with a large amount of hyperparameters.\n",
    "\n",
    "## Models to be used\n",
    "The models to be experimented with are as follows:\n",
    "- SVC\n",
    "- XGB\n",
    "- Naive Bayes\n",
    "- Random Forest Classifier\n",
    "- Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas\n",
    "from sklearn import svm, naive_bayes, ensemble, neural_network, metrics\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data, meta = arff.loadarff('emobase2010.old.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pandas.DataFrame.from_records(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns = data.dtype.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove neutral, unknown and other classes\n",
    "a = df['class']!=b'NEU'\n",
    "b = df['class']!=b'UNK'\n",
    "c = df['class']!=b'OTH'\n",
    "df = df.loc[a&b&c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'DIS'    467\n",
       "b'SUR'    452\n",
       "b'ACC'    450\n",
       "b'ANT'    412\n",
       "b'SAD'    285\n",
       "b'FEA'    239\n",
       "b'JOY'    226\n",
       "b'ANG'    212\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adata = df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, labels = np.split(adata, [-1], axis=1)\n",
    "labels = [s for s in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2743, 1)\n",
      "[0 3 0 ..., 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(labels))\n",
    "le = LabelEncoder()\n",
    "labels = [s[0] for s in labels]\n",
    "le.fit(labels)\n",
    "labels = le.transform(labels)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wclf = svm.SVC(kernel='linear', class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = cross_val_predict(wclf, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24462267590229675"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(labels, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17025154939846884 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "# rough baseline -- majority class\n",
    "print(467/len(labels), 1/6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright so this is a pretty good score considering the rough baseline, unfortunately using Bayesian Optimization proved to be computationally prohibitive for the SVC. I provided the code to run it below, but was unable to finish it on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svceval(C, gamma):\n",
    "    \n",
    "    params['C'] = float(C)\n",
    "    params['gamma'] = float(gamma)\n",
    "    \n",
    "    wclf = svm.SVC(kernel='linear', class_weight='balanced', **params)\n",
    "    \n",
    "    predicted = cross_val_predict(wclf, features, labels)\n",
    "    \n",
    "    return metrics.accuracy_score(labels, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |         C |     gamma | \n"
     ]
    }
   ],
   "source": [
    "num_rounds = 3000\n",
    "random_state = 2017\n",
    "num_iter = 10\n",
    "init_points = 5\n",
    "params = {}\n",
    "\n",
    "xgbBO = BayesianOptimization(svceval, {'C': (0.001, 100), \n",
    "                                       'gamma': (0.0001, 0.1)\n",
    "                                        })\n",
    "\n",
    "xgbBO.maximize(init_points=init_points, n_iter=num_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wclf = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = cross_val_predict(wclf, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30441122858184472"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(labels, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ok, so we can see that the regular XGB improves the baseline pretty dramatically. Now let's define a function for our Bayesian Optimizer to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgbeval(min_child_weight,\n",
    "                 colsample_bytree,\n",
    "                 max_depth,\n",
    "                 subsample,\n",
    "                 gamma):\n",
    "\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['colsample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['subsample'] = max(min(subsample, 1), 0)\n",
    "    params['gamma'] = max(gamma, 0)\n",
    "    wclf = xgb.XGBClassifier(**params)\n",
    "    \n",
    "    predicted = cross_val_predict(wclf, features, labels)\n",
    "    \n",
    "    return metrics.accuracy_score(labels, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we optimize the function, warning: this will take a super long time to run. It may be advisable to run it on a server or just simply look at the output attatched to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "    1 | 04m48s | \u001b[35m   0.31134\u001b[0m | \u001b[32m            0.3366\u001b[0m | \u001b[32m   2.1001\u001b[0m | \u001b[32m     9.4543\u001b[0m | \u001b[32m            6.0659\u001b[0m | \u001b[32m     0.8636\u001b[0m | \n",
      "    2 | 08m54s |    0.29202 |             0.8072 |    0.7104 |      8.9388 |             2.7824 |      0.6164 | \n",
      "    3 | 03m07s |    0.30587 |             0.2928 |    5.1080 |      9.3488 |             9.3586 |      0.5261 | \n",
      "    4 | 06m07s |    0.29821 |             0.7249 |    8.5479 |     14.4441 |            12.0732 |      0.5231 | \n",
      "    5 | 03m26s |    0.30623 |             0.4091 |    2.7943 |     10.7828 |            19.6571 |      0.6007 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "    6 | 02m05s |    0.30660 |             0.1000 |    0.0000 |     14.9379 |            13.0542 |      0.6680 | \n",
      "    7 | 01m45s |    0.30222 |             0.1000 |   10.0000 |      5.0000 |            20.0000 |      1.0000 | \n",
      "    8 | 07m38s |    0.30113 |             1.0000 |    0.0000 |      5.0000 |            20.0000 |      1.0000 | \n",
      "    9 | 04m26s |    0.29894 |             0.1736 |    9.7862 |     14.2653 |             1.1187 |      0.9952 | \n",
      "   10 | 94m00s |    0.29603 |             0.2528 |    9.8876 |      5.2622 |             1.4550 |      0.9842 | \n",
      "   11 | 02m45s |    0.30623 |             0.1567 |    8.5372 |     14.9318 |            19.8032 |      0.9669 | \n",
      "   12 | 02m02s |    0.29821 |             0.1320 |    0.0013 |      5.2846 |            12.4111 |      0.9144 | \n",
      "   13 | 02m37s |    0.31061 |             0.1760 |    0.3862 |     14.8381 |            19.7863 |      0.8938 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  3.55870347e-05]), 'funcalls': 52, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   14 | 02m44s |    0.31061 |             0.1076 |    2.6737 |     14.6929 |             7.0232 |      0.9564 | \n",
      "   15 | 13m30s |    0.30806 |             0.9887 |    1.2976 |     11.8162 |             8.8511 |      0.9865 | \n"
     ]
    }
   ],
   "source": [
    "num_rounds = 3000\n",
    "random_state = 2017\n",
    "num_iter = 10\n",
    "init_points = 5\n",
    "params = {}\n",
    "\n",
    "xgbBO = BayesianOptimization(xgbeval, {'min_child_weight': (1, 20),\n",
    "                                                'colsample_bytree': (0.1, 1),\n",
    "                                                'max_depth': (5, 15),\n",
    "                                                'subsample': (0.5, 1),\n",
    "                                                'gamma': (0, 10)\n",
    "                                                })\n",
    "xgbBO.maximize(init_points=init_points, n_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results\n",
      "XGBOOST: 0.311338\n",
      "Best Params: {'subsample': 0.86358306525373618, 'colsample_bytree': 0.33658558928849269, 'max_depth': 9.4543347834429881, 'min_child_weight': 6.0659314521001315, 'gamma': 2.1000619104831797}\n"
     ]
    }
   ],
   "source": [
    "print('Final Results')\n",
    "print('XGBOOST: %f' % xgbBO.res['max']['max_val'])\n",
    "print('Best Params: {}'.format(xgbBO.res['max']['max_params']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, a little dissapointing that a couple hours only got us about another percent of accuracy out of it. Lets repeat the process for other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wclf = naive_bayes.GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = cross_val_predict(wclf, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20889537003281078"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(labels, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so that's not so good, and the downside is that because the Naive Bayes is so simple it doesn't allow for hyperparameter tuning as there are no hyperparameters to tune. We can use this as a good baseline however. Let's move on to something more interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "Kind of the little brother of XGB, Random Forests represent a very reasonable model choice for a lot of tasks. With the addition of many hyperparameters we can see how much more accuracy we can squeeze out with Bayesian Optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wclf = ensemble.RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = cross_val_predict(wclf, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23769595333576377"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(labels, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so that's with entirely default parameters, now let's tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rfeval(n_estimators,\n",
    "          max_depth,\n",
    "          min_samples_split,\n",
    "          min_samples_leaf,\n",
    "          min_weight_fraction_leaf,\n",
    "          min_impurity_split):\n",
    "    \n",
    "    params['n_estimators'] = int(n_estimators)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['min_samples_split'] = float(min_samples_split)\n",
    "    params['min_samples_leaf'] = float(min_samples_leaf)\n",
    "    params['min_weight_fraction_leaf'] = float(min_weight_fraction_leaf)\n",
    "    params['min_impurity_split'] = float(min_impurity_split)\n",
    "    wclf = ensemble.RandomForestClassifier(**params)\n",
    "    \n",
    "    predicted = cross_val_predict(wclf, features, labels)\n",
    "    \n",
    "    return metrics.accuracy_score(labels, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   max_depth |   min_impurity_split |   min_samples_leaf |   min_samples_split |   min_weight_fraction_leaf |   n_estimators | \n",
      "    1 | 00m03s | \u001b[35m   0.17025\u001b[0m | \u001b[32m     8.2271\u001b[0m | \u001b[32m              1.3648\u001b[0m | \u001b[32m            0.1369\u001b[0m | \u001b[32m             0.7024\u001b[0m | \u001b[32m                    0.4156\u001b[0m | \u001b[32m        6.2759\u001b[0m | \n",
      "    2 | 00m03s |    0.17025 |      8.9579 |               4.0618 |             0.4170 |              0.7289 |                     0.4430 |        19.2143 | \n",
      "    3 | 00m02s |    0.17025 |      5.0506 |               3.1692 |             0.4092 |              0.5973 |                     0.4241 |        11.2262 | \n",
      "    4 | 00m03s | \u001b[35m   0.23077\u001b[0m | \u001b[32m    11.5825\u001b[0m | \u001b[32m              0.7003\u001b[0m | \u001b[32m            0.0880\u001b[0m | \u001b[32m             0.5905\u001b[0m | \u001b[32m                    0.2103\u001b[0m | \u001b[32m       14.3346\u001b[0m | \n",
      "    5 | 00m02s |    0.16843 |     12.9565 |               1.5326 |             0.3901 |              0.5660 |                     0.2164 |         2.6063 | \n",
      "    6 | 00m03s |    0.17025 |      6.3681 |               1.7784 |             0.4029 |              0.2128 |                     0.3416 |        15.9320 | \n",
      "    7 | 00m03s |    0.17025 |      6.5224 |               4.9992 |             0.4784 |              0.9419 |                     0.1658 |         8.6628 | \n",
      "    8 | 00m03s |    0.17025 |      9.8737 |               1.8264 |             0.1284 |              0.4698 |                     0.0814 |         6.7998 | \n",
      "    9 | 00m02s |    0.16843 |     13.4392 |               2.9592 |             0.3172 |              0.1896 |                     0.3485 |        12.6945 | \n",
      "   10 | 00m02s |    0.17025 |      9.9343 |               4.5726 |             0.2107 |              0.1686 |                     0.3318 |        14.0482 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   max_depth |   min_impurity_split |   min_samples_leaf |   min_samples_split |   min_weight_fraction_leaf |   n_estimators | \n",
      "   11 | 00m22s |    0.17025 |     15.0000 |               0.0000 |             0.0000 |              1.0000 |                     0.0000 |        20.0000 | \n",
      "   12 | 00m11s |    0.16624 |      5.0000 |               0.0000 |             0.0000 |              1.0000 |                     0.0000 |         1.0000 | \n",
      "   13 | 00m11s |    0.17025 |     15.0000 |               0.0000 |             0.0000 |              1.0000 |                     0.0000 |         9.4732 | \n",
      "   14 | 00m13s |    0.17025 |     10.2060 |               0.0000 |             0.5000 |              1.0000 |                     0.0000 |        15.5820 | \n",
      "   15 | 00m17s |    0.16806 |      5.0000 |               5.0000 |             0.0000 |              0.0000 |                     0.5000 |         1.0000 | \n",
      "   16 | 00m23s |    0.17025 |      5.0000 |               5.0000 |             0.0000 |              0.0000 |                     0.0000 |        20.0000 | \n",
      "   17 | 00m22s |    0.16405 |     15.0000 |               5.0000 |             0.0000 |              1.0000 |                     0.5000 |         1.0000 | \n",
      "   18 | 00m17s |    0.19176 |     15.0000 |               0.0000 |             0.0000 |              0.0000 |                     0.5000 |         1.0000 | \n",
      "   19 | 00m16s | \u001b[35m   0.23952\u001b[0m | \u001b[32m    13.6140\u001b[0m | \u001b[32m              0.0000\u001b[0m | \u001b[32m            0.0000\u001b[0m | \u001b[32m             0.0000\u001b[0m | \u001b[32m                    0.5000\u001b[0m | \u001b[32m       15.2473\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  1.50365112e-05]), 'funcalls': 49, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   20 | 00m13s |    0.17025 |     15.0000 |               5.0000 |             0.0000 |              0.0000 |                     0.5000 |        20.0000 | \n",
      "   21 | 00m16s | \u001b[35m   0.24353\u001b[0m | \u001b[32m    11.4489\u001b[0m | \u001b[32m              0.0000\u001b[0m | \u001b[32m            0.0000\u001b[0m | \u001b[32m             0.0000\u001b[0m | \u001b[32m                    0.5000\u001b[0m | \u001b[32m       11.4352\u001b[0m | \n",
      "   22 | 00m15s |    0.24098 |      7.3848 |               0.0000 |             0.0000 |              0.0000 |                     0.5000 |        20.0000 | \n",
      "   23 | 00m14s |    0.23697 |      5.3645 |               0.0000 |             0.0000 |              0.3338 |                     0.5000 |        20.0000 | \n",
      "   24 | 00m11s |    0.22895 |      8.7176 |               0.0000 |             0.0000 |              0.0000 |                     0.5000 |        11.8383 | \n",
      "   25 | 00m13s |    0.17025 |     10.8394 |               0.8673 |             0.0000 |              0.0000 |                     0.5000 |        19.6535 | \n",
      "   26 | 00m17s | \u001b[35m   0.26686\u001b[0m | \u001b[32m    12.0298\u001b[0m | \u001b[32m              0.0000\u001b[0m | \u001b[32m            0.0000\u001b[0m | \u001b[32m             0.0000\u001b[0m | \u001b[32m                    0.0000\u001b[0m | \u001b[32m       13.3269\u001b[0m | \n",
      "   27 | 00m17s |    0.26394 |      5.0000 |               0.0000 |             0.0000 |              0.0000 |                     0.0000 |         8.1535 | \n",
      "   28 | 00m13s | \u001b[35m   0.26941\u001b[0m | \u001b[32m     5.0000\u001b[0m | \u001b[32m              0.0000\u001b[0m | \u001b[32m            0.0000\u001b[0m | \u001b[32m             0.0000\u001b[0m | \u001b[32m                    0.0000\u001b[0m | \u001b[32m        5.5068\u001b[0m | \n",
      "   29 | 00m14s |    0.17025 |      5.0000 |               2.9473 |             0.0000 |              0.0000 |                     0.0000 |         5.8683 | \n",
      "   30 | 00m16s |    0.17025 |      5.0000 |               0.0000 |             0.5000 |              0.0000 |                     0.5000 |         7.2854 | \n",
      "   31 | 00m18s |    0.19686 |      9.8346 |               0.0000 |             0.0000 |              0.0000 |                     0.0000 |         1.0000 | \n",
      "   32 | 00m15s |    0.17025 |      5.0000 |               0.0000 |             0.0000 |              1.0000 |                     0.0000 |        12.6054 | \n",
      "   33 | 00m19s |    0.16843 |     10.4234 |               5.0000 |             0.0000 |              0.0000 |                     0.0000 |         1.0000 | \n",
      "   34 | 00m15s |    0.17025 |     15.0000 |               5.0000 |             0.0000 |              0.0000 |                     0.0000 |         5.9197 | \n",
      "   35 | 00m29s |    0.16843 |      5.0000 |               5.0000 |             0.0000 |              0.0000 |                     0.0000 |        12.3386 | \n"
     ]
    }
   ],
   "source": [
    "num_iter = 25\n",
    "init_points = 10\n",
    "params = {}\n",
    "\n",
    "xgbBO = BayesianOptimization(rfeval, {'n_estimators': (1, 20),\n",
    "                                                'max_depth': (5, 15),\n",
    "                                                'min_samples_split': (1e-10, 1),\n",
    "                                                'min_samples_leaf': (1e-10, 0.5),\n",
    "                                                'min_weight_fraction_leaf': (1e-10, 0.5),\n",
    "                                                'min_impurity_split': (1e-10,5)\n",
    "                                                })\n",
    "xgbBO.maximize(init_points=init_points, n_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Final Results')\n",
    "print('XGBOOST: %f' % xgbBO.res['max']['max_val'])\n",
    "print('Best Params: {}'.format(xgbBO.res['max']['max_params']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to improve it a decent amount, now let's try it on a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wclf = neural_network.MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = cross_val_predict(wclf, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30441122858184472"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(labels, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, doing approximately the same as the XGB. Now let's see how much we can improve this baseline with hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nneval(hidden_layer_sizes,\n",
    "          alpha,\n",
    "          max_iter,\n",
    "          momentum\n",
    "          ):\n",
    "    \n",
    "    params['hidden_layer_sizes'] = int(hidden_layer_sizes)\n",
    "    params['alpha'] = float(alpha)\n",
    "    params['max_iter'] = int(max_iter)\n",
    "    params['momentum'] = float(momentum)\n",
    "    wclf = neural_network.MLPClassifier(**params)\n",
    "    \n",
    "    predictions = cross_val_predict(wclf, features, labels)\n",
    "    \n",
    "    return metrics.accuracy_score(labels, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   hidden_layer_sizes |   max_iter |   momentum | \n",
      "    1 | 00m22s | \u001b[35m   0.30441\u001b[0m | \u001b[32m   0.5979\u001b[0m | \u001b[32m            295.0528\u001b[0m | \u001b[32m  102.4887\u001b[0m | \u001b[32m    0.3906\u001b[0m | \n",
      "    2 | 01m41s |    0.30441 |    0.3655 |            1507.8652 |   306.6683 |     0.4306 | \n",
      "    3 | 00m13s |    0.30441 |    0.9130 |             191.5456 |   470.4478 |     0.0219 | \n",
      "    4 | 02m02s |    0.30441 |    0.3403 |            1969.1696 |   483.9889 |     0.0304 | \n",
      "    5 | 01m29s |    0.30441 |    0.8284 |            1329.8292 |   538.2416 |     0.7872 | \n",
      "    6 | 00m22s |    0.30441 |    0.4696 |             336.2538 |   387.0172 |     0.2317 | \n",
      "    7 | 01m50s |    0.30441 |    0.8471 |            1496.2960 |   371.1876 |     0.5711 | \n",
      "    8 | 01m40s |    0.30441 |    0.6670 |            1248.6818 |   666.7233 |     0.2567 | \n",
      "    9 | 00m17s |    0.30441 |    0.2974 |             225.4734 |   893.6167 |     0.8692 | \n",
      "   10 | 03m25s |    0.30441 |    0.3667 |            1928.3350 |   222.1918 |     0.4214 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   hidden_layer_sizes |   max_iter |   momentum | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   11 | 03m13s |    0.30441 |    0.2509 |            1995.2197 |   996.0094 |     0.6781 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   12 | 00m44s |    0.30441 |    0.0326 |             944.7270 |     6.6165 |     0.0500 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   13 | 01m20s |    0.30441 |    0.9516 |             781.6838 |   994.5673 |     0.9263 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   14 | 00m17s |    0.30441 |    0.8792 |               5.3752 |   954.7635 |     0.8511 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15 | 00m19s |    0.30441 |    0.4225 |              11.8761 |    11.9248 |     0.8719 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   16 | 01m19s |    0.30441 |    0.4933 |            1453.3378 |   994.7019 |     0.6449 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   17 | 00m53s |    0.30441 |    0.2218 |             735.5566 |   398.9625 |     0.5321 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   18 | 01m50s |    0.30441 |    0.7276 |            1996.9570 |    20.6846 |     0.8805 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19 | 00m39s |    0.30441 |    0.7178 |             539.5538 |    28.6458 |     0.0440 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   20 | 02m01s |    0.30441 |    0.8036 |            1720.8840 |   807.6312 |     0.2702 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   21 | 01m09s |    0.30441 |    0.0302 |            1433.6540 |     9.7319 |     0.0121 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   22 | 00m35s |    0.30441 |    0.6554 |             556.6435 |   421.0155 |     0.4299 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   23 | 00m31s |    0.30441 |    0.7291 |             361.8453 |   640.5830 |     0.2992 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   24 | 03m22s |    0.30441 |    0.8326 |            1864.7208 |   493.5720 |     0.4627 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 | 01m21s |    0.30441 |    0.5694 |             963.4945 |   445.7804 |     0.5866 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   26 | 01m04s |    0.30441 |    0.7661 |             912.7508 |   116.4773 |     0.0510 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   27 | 00m18s |    0.30441 |    0.0948 |             111.0786 |   838.6054 |     0.7529 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   28 | 01m19s |    0.30441 |    0.2078 |            1221.6622 |   867.6947 |     0.2643 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   29 | 01m43s |    0.30441 |    0.8030 |            1185.6962 |   624.9690 |     0.6572 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   30 | 01m22s |    0.30441 |    0.7703 |             967.0266 |   437.7335 |     0.3943 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   31 | 00m22s |    0.30441 |    0.0801 |              96.5543 |   254.3581 |     0.9190 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   32 | 00m50s |    0.30441 |    0.4010 |             804.5094 |   870.6812 |     0.2646 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   33 | 01m42s |    0.30441 |    0.0065 |            1440.7139 |   754.4995 |     0.6870 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   34 | 00m34s |    0.30441 |    0.2522 |             407.6040 |   163.0261 |     0.2908 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   35 | 00m26s |    0.30441 |    0.1964 |             131.2935 |   273.7879 |     0.1751 | \n"
     ]
    }
   ],
   "source": [
    "num_iter = 25\n",
    "init_points = 10\n",
    "params = {}\n",
    "\n",
    "xgbBO = BayesianOptimization(nneval, {'hidden_layer_sizes': (1, 2000),\n",
    "                                                'alpha': (0, 1),\n",
    "                                                'max_iter': (1, 1000),\n",
    "                                                'momentum': (0, 1),\n",
    "                                                })\n",
    "\n",
    "xgbBO.maximize(init_points=init_points, n_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results\n",
      "XGBOOST: 0.304411\n",
      "Best Params: {'hidden_layer_sizes': 295.05280471785909, 'momentum': 0.39058478805905594, 'max_iter': 102.48867041393048, 'alpha': 0.59790180250810609}\n"
     ]
    }
   ],
   "source": [
    "print('Final Results')\n",
    "print('XGBOOST: %f' % xgbBO.res['max']['max_val'])\n",
    "print('Best Params: {}'.format(xgbBO.res['max']['max_params']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly Bayesian Optimization doesn't seem to help the neural network for several reasons, one of which is that when predicting the level of the max iterations it can cause non-convergence if it sets it too low. It seems that, for neural networks at least, it helps much more to actually know what you're doing when setting the hyperparameters. Bayesian Optimization can theoretically help with setting the proper hidden layer size, which I will test below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nneval(hidden_layer_sizes):\n",
    "    \n",
    "    params['hidden_layer_sizes'] = int(hidden_layer_sizes)\n",
    "    wclf = neural_network.MLPClassifier(**params)\n",
    "    \n",
    "    predictions = cross_val_predict(wclf, features, labels)\n",
    "    \n",
    "    return metrics.accuracy_score(labels, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m----------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   hidden_layer_sizes | \n",
      "    1 | 00m22s | \u001b[35m   0.30441\u001b[0m | \u001b[32m            452.1221\u001b[0m | \n",
      "    2 | 00m21s |    0.30441 |             322.6510 | \n",
      "    3 | 00m59s |    0.30441 |            1072.1705 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m----------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   hidden_layer_sizes | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    4 | 02m47s |    0.30441 |            1999.9397 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    5 | 00m13s |    0.30441 |               1.0021 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    6 | 01m38s |    0.30441 |            1582.0588 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    7 | 00m45s |    0.30441 |             769.3950 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    8 | 01m37s |    0.30441 |            1337.1105 | \n"
     ]
    }
   ],
   "source": [
    "num_iter = 5\n",
    "init_points = 3\n",
    "params = {}\n",
    "\n",
    "xgbBO = BayesianOptimization(nneval, {'hidden_layer_sizes': (1, 2000)})\n",
    "\n",
    "xgbBO.maximize(init_points=init_points, n_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results\n",
      "XGBOOST: 0.304411\n",
      "Best Params: {'hidden_layer_sizes': 452.12210527070141}\n"
     ]
    }
   ],
   "source": [
    "print('Final Results')\n",
    "print('XGBOOST: %f' % xgbBO.res['max']['max_val'])\n",
    "print('Best Params: {}'.format(xgbBO.res['max']['max_params']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It actually looks like the hidden layer size has extremely little affect on the overall performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling Models\n",
    "\n",
    "Let's just do one last experiment to see how high of an accuracy we can feasibly get. I'll build an ensemble model of 3 XGB's with the optimized hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'subsample': 0.86358306525373618, \n",
    "          'colsample_bytree': 0.33658558928849269, \n",
    "          'max_depth': 9.4543347834429881, \n",
    "          'min_child_weight': 6.0659314521001315, \n",
    "          'gamma': 2.1000619104831797}\n",
    "\n",
    "params['min_child_weight'] = int(params['min_child_weight'])\n",
    "params['colsample_bytree'] = max(min(params['colsample_bytree'], 1), 0)\n",
    "params['max_depth'] = int(params['max_depth'])\n",
    "params['subsample'] = max(min(params['subsample'], 1), 0)\n",
    "params['gamma'] = max(params['gamma'], 0)\n",
    "\n",
    "clf1 = xgb.XGBClassifier(**params)\n",
    "clf2 = xgb.XGBClassifier(**params)\n",
    "clf3 = xgb.XGBClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3113379511483777"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wclf = ensemble.VotingClassifier(estimators=[('xgb', clf1), ('xgb', clf2), ('xgb', clf3)])\n",
    "predictions = cross_val_predict(wclf, features, labels)\n",
    "metrics.accuracy_score(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we don't really get a boost with the ensembling unfortunately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "SVC | SVC w/ BO | XGB | XGB w/ BO | NB | RF | RF w/ BO | MLP | MLP w/ BO | XGB Ensemble\n",
    "--- | --- | --- | --- | --- | --- | --- | --- | --- | ---\n",
    "0.245  |  dnf  |  0.304  |  0.311  |  0.208  |  0.237  | 0.269  | 0.304  |  0.304 | 0.311"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "As we can see from the above results, XGB has again proved to be the highest performing model. Beyond that, we have seen that Bayesian Optimization can improve the performance of all decision tree based algorithms, but does not seem to be effective for the MLP. In the next experiment, we will take these results and see how feature normalization/dimensionality reduction will affect our accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
